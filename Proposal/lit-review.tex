\chapter{Literature Review}
\label{cha:lit-review}

It is widely accepted that the universe follows the \gls{lcdm} model, that is, a spatially flat cosmology comprised of dark energy, cold dark matter, and ordinary (baryonic) matter \citep[see e.g.][for further discussions on cosmological models]{planck_collaboration_planck_2020, lee_shape_2025}. The many complex components of this paradigm pose challenges to understanding the formation and evolution of galaxies, however, significant strides have been made both through observations and simulations in working towards this goal. This chapter contextualises my thesis within the vast array of existing literature concerning the characterisation of galaxies. More specifically, it will unpack observational and numerical contributions to theories of galaxy formation, assessing the relationship between hierarchical star formation and internal and external processes affecting composite stellar populations.

The relevant background information for this thesis can be categorised under two themes: theory and computation. Section \ref{sec:theory} of this chapter will discuss galaxy parametrisation, relating the formation of individual stellar populations within a galaxy to its broader conditions. This section will also include a brief overview of \textit{FSPS}, a Python library for synthetically generating stellar populations within a galaxy from input parameters. Section \ref{sec:software} will further focus on studies in computational astronomy which have worked towards resolving galaxy parameters, outlining the evolution from pure \gls{sps} to \gls{sps}-driven machine-learning techniques. Finally, Section \ref{sec:tc} will delve deeper into \tc to clarify its role as the algorithmic framework for this project. Through this, I will demonstrate the role of my project both in the development of machine-learning technologies for astronomy, and the applications of such technology in further understanding a crucial structural cosmological component.

\section{How to Build a Galaxy}
\label{sec:theory}

Galaxies are shaped by a core set of physical processes --- cosmological accretion, strong stellar-driven winds, black hole feedback, and morphological evolution --- which exist in dialogue with hierarchical bursts of star formation \citep{somerville_physical_2015}. A galaxy's spectrum acts as its fingerprint, revealing these intersecting cosmological and stellar factors which affect its global properties and demographics. Difficulties arise when disentangling individual signatures from the complex web of a galaxy's \gls{sed}, which is why its interpretation often involves working backwards using \gls{sps} techniques. That is, creating a model to generate a synthetic galaxy spectrum using a series of input parameters, in an attempt to recreate an observed \gls{sed} and therefore estimate parameter values from the model \citep{courteau_galaxy_2014}.

When it comes to creating these model spectra, \cite{conroy_modeling_2013} identifies five fundamental properties of unresolved stellar populations that are encoded in galaxy \glspl{sed}:
\begin{enumerate}
    \item \gls{sfh}
    \item Stellar metallicity and abundance pattern
    \item Stellar \gls{imf}
    \item Total mass in stars
    \item The physical state and quantity of dust and gas
\end{enumerate}
By varying these five properties as input parameters, \gls{sps} models can recreate galaxy \glspl{sed} and achieve a reasonable galaxy characterisation. At the same time, scaling relations between the properties of \glspl{ssp} within a galaxy, such as velocity dispersion and stellar masses, are also affected by these global parameters, in addition to overall rotation \citep{mcdermid_atlas3d_2015}. As such, understanding the \glspl{ssp} of a galaxy is critical to unlocking its \gls{sed}. I will thus focus on \gls{sfh} as the key parameter linking the evolution of a galaxy with its constituent stellar populations.

\subsection{Star Formation Histories}

Star formation history refers to the distribution of stellar generations in time and chemical enrichment, and can often be described by analytic laws which depend on the time scale of the \gls{sfr}. Particularly for low-redshift galaxies, \gls{sfh} can be used to trace old stellar populations, while \glspl{sfh} of high-redshift galaxies shed light into earlier bursts of star formation \citep{lopez-corredoira_age_2024}. As demonstrated in Fig. \ref{fig:macarthur}, stellar evolution tracks can vary significantly with different \gls{sfh} functions, making it a key component of galaxy evolution, and in turn affecting \glspl{sed}. This is because each generation of stars that comprises a \gls{sfh} is its own \gls{ssp}. However, the nature of an \gls{ssp} is determined by initial conditions, that is, the metallicity and elemental abundances of the \gls{ism} within the galaxy it forms in, as described by Eq. \ref{eq:conroy} \citep[from][]{conroy_modeling_2013}. 

\begin{equation}
    f_\text{SSP}(t,Z)=\int_{m_l}^{m_u(t)}f_\text{star}\left[T_\text{eff}(M),\log{g}(M)|t,Z\right]\Phi(M)\text{d}M
    \label{eq:conroy}
\end{equation}

In the above, $M$ is the zero-age main sequence stellar mass, $\Phi(M)$ is the \gls{imf}, $f_\text{star}$ is a base stellar spectrum, and $f_\text{SSP}$ is the resulting \gls{ssp} spectrum, dependent on time $(t)$ and metallicity $(Z)$. The integration boundaries $(m_l$ and $m_u)$ are given by masses related to stellar evolution. Arguably, there is a circular relationship between galactic conditions and the nature of \glspl{ssp} that make up a galaxy's \gls{sfh}. The isochrone that determines the relation between $T_\text{eff}$, $\log{g}$, and $M$ for a given $t$ and $Z$ in Eq. \ref{eq:conroy} is dependent on the metallicity of the nebular matter out of which is forms (i.e. the galaxy). The temporal combination of \glspl{ssp} (i.e. the \gls{sfh}), as well as their metallicity and abundance patterns, are in turn two of the five fundamental parameters that determine a galaxy's \gls{sed}, as aforementioned.

\begin{figure}[!h]
    \includegraphics[width=0.8\textwidth]{Proposal/figs/fg5.pdf}
    \centering
    \caption{Comparison of stellar population model tracks for exponential (blue) and "Sandage" (red) star formation histories. From \citet{macarthur_structure_2004}.}
    \label{fig:macarthur}
\end{figure}

Therefore, the parameters of a galaxy and of the stellar populations it harbours are intrinsically linked. This is also asserted by \citet{silva-lima_optimizing_2025}, who observe that stellar evolution occurs faster in the inner galactic regions due to increased activity like star formation, shock, gas accretion, and inflows and outflows of ionised gas. They use this to interpret, through reproduction, the observed spectra of the central region of NGC 613. Through this, its \gls{sfh} is also recovered, demonstrating the inherent relationship between galactic activity, \gls{sfh}, and spectra.

\subsection{SFH and Metallicity Evolution}

Integral to both galaxy \glspl{sed} and \gls{sfh} is the evolution of stellar metallicities and abundance patterns which affect the overall metallicity of a galaxy. Notably, \citet{bellstedt_galaxy_2020} found that for all galaxy morphologies, metallicity rapidly evolves with a higher \gls{sfr} in the early universe, compared to slower rates in recent times. The authors demonstrate the significant impact of metallicity on cosmic \gls{sfh} using the \gls{sed} fitting code PROSPECT, highlighting the necessity of allowing metallicity evolution in individual galaxies when measuring their \glspl{sfh} (Fig. \ref{fig:bellstedt}).

\begin{figure}[!h]
    \includegraphics[width=0.8\textwidth]{Proposal/figs/m_staa2620fig4.pdf}
    \centering
    \caption{Effect of different metallicity assumptions on cosmic star formation rate density (SFRD), compared against observational measurements by \citet{driver_gamag10-cosmos3d-hst_2018} and fit to the compilation of measurements by \citet{madau_cosmic_2014}. The thick black line represents c\gls{sfh} derived using a closed-box metallicity evolution. From \citet{bellstedt_galaxy_2020}.}
    \label{fig:bellstedt}
\end{figure}

This demonstrates that a galaxy's metallicity evolution, which in turn dictates the metallicity of \glspl{ssp}, which then feeds back into the elemental abundances of the galactic \gls{ism}, is yet another reciprocal relationship between the parameters of a galaxy and its harbouring stellar populations. Furthermore, \citet{iyer_reconstruction_2017} note the role of the total stellar mass formed in each \gls{ssp} as both a consequence of, and contributor to, the state of metallicity abundances in the galactic \gls{ism} before and after each stellar generation, as well as of each \gls{ssp} itself. 

The crux of the matter is that galaxy parameters cannot exist in isolation. It is impossible to achieve a complete picture of \gls{sfh} without considering every other factor. For this reason, particularly within the context of machine-learning, developing training libraries with high stochasticity is the most comprehensive approach to capturing the complex and multilayered interactions between parameters. This is where \gls{ssp} models can be very useful in generating mock spectra, as demonstrated in the following sections.

\subsection{\textit{FSPS: Flexible Stellar Population Synthesis}}

\gls{fsps} \citep{conroy_propagation_2009, conroy_propagation_2010} is a Python-bound Fortran library for the creation of spectra and magnitudes for arbitrary stellar populations. It generates \glspl{ssp} by summing assigned spectral libraries along isochrones, weighted by a given \gls{imf}. Convolving the \gls{ssp} with an \gls{sfh} and other prescriptions relating to, for example, metallicity and dust attenuation, gives the present-day spectrum of a composite stellar population like a galaxy\footnote{A full list of accepted input parameters can be found in the \href{https://dfm.io/python-fsps/current/stellarpop_api/\#api-reference}{FSPS API}.}.

While the initialisation of composite stellar populations is possible with \gls{fsps}, manually generating and convolving \glspl{ssp} allows greater flexibility of input parameters while emulating different bursts of star formation across a galaxy's \gls{sfh}. The following section discusses some of the computational aspects of \gls{sps}, both as a standalone method in recreating galaxy \glspl{sed} and as a tool for more sophisticated machine learning algorithms.

\section{Methods for Galaxy Parametrisation}
\label{sec:software}

The earliest efforts towards extracting information from \glspl{sed} involved the ad hoc fitting of combined stellar mixtures until a reasonable match with observations was achieved \citep[e.g.][]{spinrad_stellar_1971}. Switching to a modular code structure pioneered by \citet{maraston_evolutionary_1998} later allowed for greater control over individual \gls{sps} input parameters, increasing the sophistication of these evolutionary models. Similar four- or five-parameter \gls{sps} models, usually including at least a simple \gls{sfh}, dust attenuation vector, and stellar metallicity, prolifically appeared in literature in the early years of this century \citep[e.g.][]{brinchmann_mass_2000, salim_uv_2007, salmon_relation_2015}, employing increasingly complex fitting techniques to reproduce observed spectra.

However, these approaches contain fundamentally large uncertainties and systematic errors, due to uncertainties in input models as well as weak observational constraints within extragalactic stellar populations resulting in high model degeneracy \citep{leja_older_2019}. That is, different sets of model parameters would produce similar observational predictions, making it difficult to draw conclusions about properties of galaxies with any level of confidence. More recent approaches, such as the 14-parameter \texttt{Prospector}-$\upalpha$ model introduced by \citet{leja_older_2019} aim to mitigate these issues using some key refinements:
\begin{itemize}
    \item Increased model components, including nebular emission during photoionisation, flexible dust attenuation curves, and superimposing random bursts into \gls{sfh} libraries.
    \item More robust statistical frameworks, like Bayesian forward-modelling techniques.
    \item Reducing computation time using gridless "on-the-fly" models combined with \gls{mcmc} algorithms to explore high-dimensional spaces.
    \item Fitting to 3D-\textit{\acrshort{hst}} photometric catalogues, providing well-parametrised high-resolution imaging to strengthen observational constraints.
\end{itemize}
Even so, model cross-validation is required verify the results of any \gls{sps} model, regardless of its sophistication, simply due to the sheer number of variables and internal dependencies in galaxy \glspl{sed}. It is for this reason that combining \gls{sps} with other methods has increased in popularity in recent years, as a way of bridging the divide between simulation and observation.

\subsection{Adaptive Parametrisation}

Unlike \gls{sps} models which define a set of parameters constraining every \gls{ssp} comprising a galaxy, adaptive parametrisation techniques vary the number of parameters on a galaxy-by-galaxy basis, thus ensuring that the resolution of synthetic spectra is consistent with the data generating it. This method was pioneered by \citet{ocvirk_steckmap_2006} and adapted by \citet{tojeiro_recovering_2007} to recover \glspl{ssp} from \gls{sdss} spectroscopic data. Rather than imposing predefined constraints to reproduce data that may not be sensitive to them, this model extracts viable parameters direct from the data. This simple modification to \gls{sps} techniques demonstrates the value of such hybrid methods.

\subsection{The Dense-Basis Approach and Principal Component Analysis}

The dense-basis formalism, introduced by \citet{iyer_reconstruction_2017}, is a fitting method for reconstructing \glspl{sfh} from a trained atlas of \glspl{sed} corresponding to the space of all physical \glspl{sfh}. \Gls{sams}, hydrodynamic simulations, and stochastic \glspl{sfh} comprise a mock catalogue, which, with the addition of some realistic synthetic noise, trains the \gls{sed} fitting model to reconstruct \glspl{sfh}. This approach is an example of \gls{pca}, an unsupervised dimensionality reduction machine-learning technique which redefines the basis of a dataset based on a linear combination of the original basis. Using covariance matrices, the data is re-ordered based on new coordinates of decreasing variance, allowing the most significant trends to be identified \citep{shlens_tutorial_2014}. In \citet{iyer_reconstruction_2017}, training the model on functional \gls{sfh} forms determined by priors minimised bias and scatter compared to traditional \gls{sfh} parametrisation.

\gls{pca} models are further discussed by \citet{zhang_testing_2025}, who use \glspl{sfh} from IllustrisTNG and EAGLE simulations to test \gls{sfh} models for the quality of their interpretations of simulated \gls{sfh} and their respective generated spectra. In a \gls{pca} model, lookback time $t_\mathrm{lb}$ is sampled on a logarithmic grid thus privileging most recent \glspl{sfr}, reflecting the fact that recent star formation has a greater influence on spectral shape that older stellar populations. As demonstrated in Figure \ref{fig:zhang}, the first ten eigenhistories obtained by \citet{zhang_testing_2025} reflect sinusoidal waves oscillating around $\mathrm{SFR}=0.0$. Higher-order eigenhistories demonstrate more frequent oscillations, therefore representing small-scale details of the \gls{sfh}, while lower order eigenhistories reflect the overall trend. More frequent oscillations for smaller lookback time further demonstrates the greater influence of more recent cosmic time in the \gls{pca} model.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Proposal/figs/apjadeb70f2_hr.pdf}
    \caption{The first ten eigenhistories of \gls{pca}-based models. Lower-order eigenhistories are given on the left panel and higher-order eigenhistories are on the right panel. Sampling on the $x$-axis is in logarithmic lookback time. From \citet{zhang_testing_2025}.}
    \label{fig:zhang}
\end{figure}

\citet{zhang_testing_2025} found that \gls{pca}-modelling successfully recovered both the overall trend and higher-order features, such as peaks, of galaxy \glspl{sfh}. However, their analysis compares purely classical \gls{pca} techniques against more traditional methods like \gls{sps}. A further technique can be added to the mix, as will now be discussed. 

\subsection{Neural Networks and Deep Learning}

Artificial neural networks are flexible, nonlinear algorithms capable of describing complex relations between input data and the target variable \citep{baron_machine_2019}. While \gls{sps} and \gls{pca} are effective in generating training spectra and a basis of galaxy \glspl{sed}, respectively, these techniques can be made significantly more powerful by training a shallow neural network to learn the \gls{pca} basis coefficients directly as a function of \gls{sps} model parameters. This is the approach taken by \citet{alsing_speculator_2020}, who apply neural networks as a convenient parametric model to emulate \gls{sps} methods for simulating galaxy spectra and photometry. Compared to traditional \gls{sps}, the authors report a factor of $\sim10^3$--$10^4$ computational speedup while maintaining percent-level accuracy over broad parameter and wavelength ranges. However, the trade-off between accuracy and computational cost of their model was not thoroughly investigated in this study, and the training sets themselves were not generated with parameter optimisation in mind.

In general, neural networks require very large amounts of data to be sufficiently trained, which can be computationally expensive. Furthermore, hyper-parametrisation has a tendency to overfit the data, requiring various corrections and causing greater difficulty in interpretation \citep{baron_machine_2019}. While neural networks can be very powerful, the expense required to train such models poses a significant barrier to keeping them up-to-date with the ever-evolving state of galactic astronomy.

A similar obstacle is met when applying deep learning architecture to recover galaxy parameters. Compared to shallow neural networks which have a single hidden layer controlling relationships between variables, deep neutral networks contain several hidden layers with interconnected dependencies. As visualised in Fig. \ref{fig:neural-networks}, tens of inputs nodes result in the modelling of only one or two free parameters, meaning that it may be effective in recovering independent global galactic parameters like age and metallicity \citep[as in][]{li_estimation_2025}, but would not be suitable for retrieving \glspl{sfh} due to the interdependent relationships between \glspl{ssp} and the \gls{ism}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=\textwidth]{Proposal/figs/deep_neural_networks.pdf}
    \caption{Visualisation of deep neural network architecture for interpreting galaxy \glspl{sed}. From \citet{surana_predicting_2020} (left) and \citet{li_estimation_2025} (right).}
    \label{fig:neural-networks}
\end{figure}

\section{\textit{The Cannon}: From Stars to Galaxies}
\label{sec:tc}

\tc \citep{ness_cannon_2015} is a supervised machine-learning algorithm which uses a data-driven approach to determine stellar labels from spectra. Trained on only 542 stars, with T$_\text{eff}$, log g, and [Fe/H] as labels, the model demonstrates a very high accuracy when applied to the spectra of 55,000 stars from \textit{\acrshort{apogee}} \acrshort{dr}10 and can theoretically be applied to stellar spectra from any survey. I will be re-training \tc to recover labels from galactic spectra, so it is important to discuss the details of how the model works, and how it may need to be adapted for the purposes of my thesis.

Regardless of whether \tc is being used for stars or galaxies, all input spectra --- including reference training sets and survey test spectra --- must meet some basic criteria:
\begin{itemize}
    \item Consistent continuum-normalisation.
    \item Consistent sampling on a rest-frame wavelength grid, with the same line-spread function.
    \item Flux variance, from photon noise and other sources, must be known at each spectral pixel of each spectrum.
\end{itemize}
As a data-driven model, the performance of \tc depends strongly on the size and quality of its training set of reference objects as it is through these that the correlations between the input spectra and labels are learned. As a generative model, an exhaustive set of labels will have been achieved when the continuum-normalised spectra of galaxies with identical labels are identical at every pixel, allowing for some intrinsic scatter and observational errors. It also needs to be presumed that for any spectrum, $n$, for any pixel, $\lambda$, the flux $f_{n\lambda}$ can be described as some smooth function of the spectrum's labels. From \citet{ness_cannon_2015}, such a model leads to the single-pixel log-likelihood function for flux, given a set of spectral model coefficients at each $\lambda$, $\pmb\theta_\lambda$, a label vector $\pmb\ell_n$, and the intrinsic variance or scatter of the model at each $\lambda$, $s_\lambda^2$:
\begin{equation}
    \ln{p}\left(f_{n\lambda}|\pmb\theta_\lambda^T,\pmb\ell_n,s_\lambda^2\right)=-\frac{1}{2}\frac{\left[f_{n\lambda}-\pmb\theta_\lambda^T\cdot\pmb\ell_n\right]^2}{s_\lambda^2+\sigma_{n\lambda}^2}-\frac{1}{2}\ln\left(s_\lambda^2+\sigma_{n\lambda}^2\right)
    \label{eq:tc-loglikelihood}
\end{equation}
As such, Eq. \ref{eq:tc-loglikelihood} provides a \gls{pdf} evaluation of all labels and parameters. The coefficients $[\pmb\theta_\lambda,s_\lambda^2]$ can then be solved by optimising the above likelihood over all reference objects using
\begin{equation}
    \pmb\theta_\lambda,s_\lambda\leftarrow\argmax_{\pmb\theta_\lambda,s_\lambda}\sum_{n=1}^N\ln{p}\left(f_{n\lambda}|\pmb\theta_\lambda^T,\pmb\ell_n,s_\lambda^2\right)
    \label{eq:trainingloglikelihood}
\end{equation}
Once the training data has been processed, \tc essentially undertakes the inverse procedure for the test step. That is, it takes the exact spectral model coefficients and scatter from the training step, the entire $N_\mathrm{pix}$ spectrum of survey spectrum $m$, $f_{m\lambda}$, and optimises for the label of that spectrum:
\begin{equation}
    \left\{\ell_{mk}\right\}\leftarrow\argmax_{\{\ell_{mk}\}}\sum_{\lambda=1}^{N_\mathrm{pix}}\ln{p}\left(f_{m\lambda}|\pmb\theta_\lambda^T,\pmb\ell_m,s_\lambda^2\right)
    \label{eq:testloglikelihood}
\end{equation}
Eq. \ref{eq:trainingloglikelihood} and Eq. \ref{eq:testloglikelihood} can therefore be seen as analogous, although it is important to note the distinction that the test step optimises over labels considering all pixels of one survey object at a time, while the training step optimises over the spectral model coefficients and scatter considering all reference objects one pixel at a time.

While there are some key differences between galaxy \glspl{sed} and stellar spectra, most ostensibly in the choice of parametrisation labels, training and implementing \tc for the purposes of my thesis is thus a relatively straightforward procedure. The following chapter will explore the details of my proposed methodology. 
